LINE-BY-LINE EXPLANATION: src/core/dataset.py
Dataset and Data Loading for Plant Disease Classification

================================================================================
PURPOSE OF THIS FILE:
================================================================================
This file handles everything related to loading and preprocessing plant disease
images for training. It's responsible for:

1. Loading images from disk
2. Organizing them by class (disease type)
3. Applying augmentation (creating variations of images)
4. Creating batches for efficient GPU processing
5. Managing train/validation splits

Think of it as the "data pipeline" - feeds data to the model during training.

================================================================================
KEY CONCEPTS BEFORE WE START
================================================================================

DATASET vs DATALOADER:
- Dataset: Knows how to load ONE image at a time
- DataLoader: Loads BATCHES of images in parallel, shuffles, handles workers

TRANSFORMS:
- Operations applied to images (resize, rotate, normalize, etc.)
- Training transforms: include augmentation (create variations)
- Validation transforms: only necessary operations (no augmentation)

BATCHING:
- Instead of processing 1 image at a time, process 32 together
- Much faster on GPU (parallel processing)
- batch_size = how many images processed together

================================================================================
IMPORTS SECTION (Lines 17-24)
================================================================================

Line 17: import torch
- Main PyTorch library for tensors and operations

Line 18: from torch.utils.data import Dataset, DataLoader, random_split
- Dataset: Base class for creating custom datasets
- DataLoader: Efficient batch loading with multiprocessing
- random_split: Split dataset into train/validation sets

Line 19: from torchvision import transforms
- Image transformations (resize, rotate, normalize, etc.)
- torchvision = PyTorch's computer vision library

Line 20: from PIL import Image
- Python Imaging Library for loading/manipulating images
- PIL.Image.open() loads jpg/png files

Line 21: from pathlib import Path
- Modern Python file path handling

Line 22: from typing import List, Tuple, Dict, Optional
- Type hints for better code documentation
- List[Path] = list of Path objects
- Optional[int] = int or None

Line 23: import json
- For saving/loading class mapping as JSON

================================================================================
PLANTDISEASEDATASET CLASS (Lines 27-193)
================================================================================

Line 27: class PlantDiseaseDataset(Dataset):
- Custom dataset class for our plant disease images
- Inherits from torch.utils.data.Dataset
- Must implement: __init__, __len__, __getitem__

DOCSTRING (Lines 28-46):
- Explains directory structure expected
- Example: data/Apple___Apple_scab/image1.jpg
- Each subdirectory = one disease class

__init__ METHOD (Lines 48-111):
This is the constructor - runs when you create a dataset instance.

Lines 49-53: Method parameters
- data_directories: List of folders containing images
  * Can combine multiple datasets (PlantVillage + NewPlantDiseases)
  * Flexibility to use different data sources
- transform: Augmentation/preprocessing pipeline
  * Applied to each image when loaded
  * Can be None (load raw images)
- valid_extensions: Which file types to load
  * Default: .jpg, .jpeg, .png (case insensitive)

Lines 70-72: Store parameters as instance variables
- self.transform = transform
- Can access later when loading images
- self.valid_extensions for filtering files

Lines 75-76: Initialize storage lists
- self.image_paths = [] : Will store path to each image
- self.labels = [] : Will store class index for each image
- These lists stay in sync (same index = same image)

Lines 78-88: Build class mapping (FIRST PASS)
- Loop through all data directories
- Find all subdirectories (each is a class)
- Collect unique class names in a set
- Why set? Automatically handles duplicates
- Example: Both PlantVillage and NewPlantDiseases might have "Tomato_Early_blight"

Line 90-92: Sort classes for consistency
- sorted(list(all_classes)) gives alphabetical order
- Same order every time (important for reproducibility)
- Loading model later requires same class order

Lines 95-96: Create class_to_idx mapping
- Dictionary: class name -> integer index
- Example: {"Apple___Apple_scab": 0, "Tomato___Early_blight": 1, ...}
- Why? Neural networks need numeric labels, not strings

Lines 99-100: Create idx_to_class mapping
- Reverse dictionary: integer index -> class name
- Example: {0: "Apple___Apple_scab", 1: "Tomato___Early_blight", ...}
- Used for predictions: convert model output (number) to disease name

Lines 103-121: Populate image paths and labels (SECOND PASS)
- Now that we have class mapping, load actual images
- For each data directory:
  * For each class in our mapping:
    - Find class subdirectory
    - Find all image files with valid extensions
    - Add path to image_paths list
    - Add corresponding class index to labels list

Example walk-through:
- data_dir = Path("data/PlantVillage")
- class_name = "Tomato_Early_blight", class_idx = 5
- class_dir = Path("data/PlantVillage/Tomato_Early_blight")
- Find image: Path(".../ Tomato_Early_blight/image001.jpg")
- Add to lists: image_paths.append(path), labels.append(5)

Lines 123-127: Print summary
- Show total images loaded
- Show number of classes
- Show first few class names
- Useful for verifying dataset loaded correctly

__len__ METHOD (Lines 129-145):
Required by PyTorch Dataset interface.

Line 145: return len(self.image_paths)
- Returns total number of images
- Called by DataLoader to know dataset size
- Example: len(dataset) = 54306

__getitem__ METHOD (Lines 147-181):
Required by PyTorch Dataset interface.
Most important method - called thousands of times during training.

Line 147: def __getitem__(self, index: int) -> Tuple[torch.Tensor, int]:
- Takes an index (0 to len-1)
- Returns (image_tensor, label)
- Called by DataLoader for each sample

Lines 165-166: Get path and label
- image_path = self.image_paths[index]
- label = self.labels[index]
- These were populated in __init__

Lines 169-175: Load image with error handling
- Image.open(image_path) loads file from disk
- .convert('RGB') ensures 3 channels
  * Handles grayscale images (1 channel -> duplicate to 3)
  * Handles RGBA images (4 channels -> drop alpha)
- try/except prevents crashes on corrupted images
  * Returns black image as fallback
  * Prints error message for debugging

Lines 178-180: Apply transforms
- if self.transform: image = self.transform(image)
- Transforms handle:
  * Resizing to 224x224
  * Augmentation (rotation, flipping, color changes)
  * Converting PIL Image -> torch.Tensor
  * Normalization (standardize pixel values)

Line 182: return image, label
- image: torch.Tensor of shape (3, 224, 224)
- label: int (class index)
- DataLoader collects these into batches

HELPER METHODS (Lines 184-230):

get_class_name (Lines 184-198):
- Convert class index -> class name
- Example: get_class_name(5) -> "Tomato_Early_blight"
- Uses self.idx_to_class dictionary
- Returns "Unknown" if index not found (safety)

get_class_distribution (Lines 200-225):
- Count how many images in each class
- Returns: {"Apple___Apple_scab": 630, "Tomato___Early_blight": 1000, ...}
- Useful for:
  * Checking if dataset is balanced
  * Creating weighted samplers (if imbalanced)
  * Debugging data loading

save_class_mapping (Lines 227-242):
- Save class_to_idx to JSON file
- Essential for inference later
  * Model outputs class index (e.g., 5)
  * Need mapping to convert to disease name
- Creates directory if doesn't exist
- json.dump() writes human-readable JSON

================================================================================
GET_TRAIN_TRANSFORMS FUNCTION (Lines 245-298)
================================================================================

Purpose: Create augmentation pipeline for TRAINING data.

Line 245: def get_train_transforms(image_size: Tuple[int, int] = (224, 224)):
- Returns transforms.Compose (chain of transformations)
- image_size parameter allows flexibility (default 224x224 for ResNet)

Line 259: return transforms.Compose([...])
- Compose chains transforms together
- Applied in sequence: Resize -> Flip -> Rotate -> ...
- Each transform takes image and returns modified image

TRANSFORM 1 (Line 261-263): Resize
- transforms.Resize(image_size)
- Resizes image to 224x224 pixels
- Why first? All subsequent operations work on consistent size
- Maintains aspect ratio by default

TRANSFORM 2 (Line 265-268): RandomHorizontalFlip
- Flips image left-right with 50% probability
- p=0.5 means half of images will be flipped
- Why? Leaf on left vs right shouldn't matter to model
- Doubles training data diversity (free augmentation!)

TRANSFORM 3 (Line 270-273): RandomRotation
- Rotates image by random angle between -15° and +15°
- degrees=15 sets maximum rotation
- Why? Photos can be taken from different angles
- Helps model recognize diseases regardless of orientation

TRANSFORM 4 (Line 275-281): RandomResizedCrop
- First resize to larger size, then crop random region
- scale=(0.8, 1.0): crop between 80% and 100% of image
- ratio=(0.9, 1.1): maintain roughly square aspect
- Why?
  * Forces model to recognize diseases from partial views
  * Simulates zooming in/out
  * Prevents model from relying on image borders

TRANSFORM 5 (Line 283-290): ColorJitter
- Randomly adjusts brightness, contrast, saturation, hue
- Simulates different lighting conditions and cameras
- Values (0.2, 0.1) = how much to vary
  * brightness=0.2: ±20% variation
  * hue=0.1: ±10% variation
- Why?
  * Real-world photos have different lighting
  * Different cameras produce different colors
  * Model needs to be robust to these variations

TRANSFORM 6 (Line 292-295): ToTensor
- Converts PIL Image -> PyTorch tensor
- Changes: (Height, Width, Channels) -> (Channels, Height, Width)
- Scales pixels: [0, 255] integer -> [0.0, 1.0] float
- Required for neural network processing

TRANSFORM 7 (Line 297-303): Normalize
- Standardizes pixel values using ImageNet statistics
- Formula: normalized_pixel = (pixel - mean) / std
- Specific values (0.485, 0.456, 0.406) are ImageNet RGB means
- Why? ResNet50 was trained with these values
- After normalization, pixels roughly in range [-2, 2]

================================================================================
GET_VAL_TRANSFORMS FUNCTION (Lines 301-333)
================================================================================

Purpose: Create transformation pipeline for VALIDATION/TEST data.

Key differences from training transforms:
- NO augmentation (no rotation, flipping, color changes)
- Deterministic (same image always transformed same way)
- Only necessary operations: resize, tensor conversion, normalization

Why no augmentation for validation?
- Want consistent, reproducible results
- Measuring true model performance, not augmented variations
- Validation should mimic real-world inference

TRANSFORMS:
1. Resize to 224x224
2. CenterCrop (removes aspect ratio inconsistencies)
3. ToTensor (convert to tensor)
4. Normalize (same as training)

Line 324: CenterCrop
- Crops exact center region of image
- Ensures exactly 224x224 (no rounding errors)
- Deterministic (always same crop for same image)

================================================================================
CREATE_DATALOADERS FUNCTION (Lines 336-449)
================================================================================

Purpose: Factory function to create train and validation DataLoaders.

This is a convenience function that does EVERYTHING:
1. Create full dataset
2. Split into train/validation
3. Apply appropriate transforms
4. Wrap in DataLoaders

Lines 338-347: Function parameters
- data_directories: Where to load images from
- batch_size: How many images per batch (default 32)
- train_split: Fraction for training (default 0.8 = 80%)
- num_workers: Parallel processes for loading (default 4)
- pin_memory: Speed up CPU->GPU transfer (default True)
- seed: Random seed for reproducible splits (default 42)

Line 369: torch.manual_seed(seed)
- Sets random seed for reproducibility
- Same seed = same train/val split every time
- Important for comparing different experiments

Lines 372-376: Create full dataset
- PlantDiseaseDataset with transform=None
- Why None? We'll apply different transforms for train vs val
- This loads all images and builds class mapping

Lines 379-381: Calculate split sizes
- total_size = len(full_dataset) (e.g., 54306)
- train_size = int(0.8 * 54306) = 43444
- val_size = 54306 - 43444 = 10862

Lines 389-393: Split dataset
- random_split() divides dataset randomly
- generator=torch.Generator().manual_seed(seed) ensures reproducibility
- Returns two Subset objects (views into original dataset)

Lines 396-398: Apply transforms
- train_dataset gets augmentation (get_train_transforms)
- val_dataset gets minimal transforms (get_val_transforms)
- .dataset.transform accesses underlying PlantDiseaseDataset

Lines 404-413: Create training DataLoader
- DataLoader wraps dataset for efficient batch loading
- shuffle=True: Randomize order each epoch (prevents overfitting)
- num_workers=4: Use 4 processes to load data in parallel
  * While GPU trains on batch N, workers prepare batch N+1
  * Significant speedup (GPU not waiting for data)
- pin_memory=True: Allocate memory in special region for faster GPU transfer
- persistent_workers=True: Keep workers alive between epochs (faster)
- prefetch_factor=2: Load 2 batches ahead per worker

Lines 415-422: Create validation DataLoader
- Similar to training, but shuffle=False
- Why no shuffle? Consistency in validation results
- Order doesn't matter for validation accuracy calculation

Lines 424-426: Print summary
- Show number of batches in each loader
- Batches = ceil(dataset_size / batch_size)
- Example: 43444 images / 32 batch_size = 1358 batches

================================================================================
TEST CODE (Lines 452-505)
================================================================================

if __name__ == "__main__":
- Only runs when file executed directly
- Doesn't run when imported
- Tests all functionality

Test 1 (Lines 458-466): Load dataset
- Create PlantDiseaseDataset from config directories
- Verify images load correctly
- Check class mapping

Test 2 (Lines 469-473): Get single image
- dataset[0] calls __getitem__(0)
- Verify shape is correct: (3, 224, 224)
- Check label is valid integer

Test 3 (Lines 476-482): Class distribution
- Calculate images per class
- Verify classes loaded correctly
- Check for imbalance issues

Test 4 (Lines 485-492): Create dataloaders
- Test complete pipeline
- Use num_workers=0 for simpler debugging (single process)

Test 5 (Lines 495-500): Load one batch
- next(iter(train_loader)) gets first batch
- Verify batch shape: (batch_size, 3, 224, 224)
- Check labels shape: (batch_size,)

================================================================================
HOW TO USE THIS FILE
================================================================================

BASIC USAGE:
```python
from src.core.dataset import create_dataloaders
from pathlib import Path

# Create dataloaders
data_dirs = [Path("data/PlantVillage"), Path("data/NewPlantDiseases/train")]
train_loader, val_loader, dataset = create_dataloaders(
    data_directories=data_dirs,
    batch_size=32,
    train_split=0.8
)

# Training loop
for epoch in range(num_epochs):
    for images, labels in train_loader:
        # images shape: (32, 3, 224, 224)
        # labels shape: (32,)
        outputs = model(images)
        loss = criterion(outputs, labels)
        # ... backpropagation
```

CUSTOM DATASET:
```python
from src.core.dataset import PlantDiseaseDataset, get_train_transforms

# Create dataset with custom transforms
dataset = PlantDiseaseDataset(
    data_directories=[Path("data/PlantVillage")],
    transform=get_train_transforms()
)

# Save class mapping for later use
dataset.save_class_mapping(Path("models/class_mapping.json"))
```

================================================================================
KEY OPTIMIZATION TECHNIQUES
================================================================================

1. MULTIPROCESSING (num_workers):
   - Load data in parallel while GPU trains
   - CPU prepares next batch while GPU processes current batch
   - 4 workers = ~4x faster data loading

2. PIN MEMORY:
   - Allocates tensors in pinned (page-locked) memory
   - Faster CPU->GPU transfer (no page swapping)
   - Only useful when training on GPU

3. PREFETCHING:
   - Load multiple batches ahead of time
   - Ensures GPU always has data ready
   - Reduces idle time

4. PERSISTENT WORKERS:
   - Keep worker processes alive between epochs
   - Avoids overhead of creating/destroying processes
   - Faster multi-epoch training

5. AUGMENTATION ON-THE-FLY:
   - Augment images during loading (not pre-computed)
   - Saves disk space (don't store augmented images)
   - Infinite variations (different each epoch)

6. EFFICIENT TRANSFORMS:
   - Resize first (smaller images = faster subsequent ops)
   - ToTensor conversion optimized in C++
   - Normalize on GPU if possible

================================================================================
COMMON ISSUES AND SOLUTIONS
================================================================================

ISSUE: "RuntimeError: DataLoader worker exited unexpectedly"
SOLUTION: Set num_workers=0 (single process) for debugging
          Check for corrupted images in dataset

ISSUE: "Out of memory" during data loading
SOLUTION: Reduce batch_size
          Reduce num_workers (each worker uses memory)

ISSUE: "Dataset takes too long to initialize"
SOLUTION: Check if directories exist before loading
          Use fewer data directories
          Consider caching image paths

ISSUE: "Class mapping changes between runs"
SOLUTION: Sort classes (already done in code)
          Save and load class_mapping.json consistently

ISSUE: "Training slow, GPU underutilized"
SOLUTION: Increase num_workers (more parallel loading)
          Increase prefetch_factor
          Enable pin_memory

================================================================================
AUGMENTATION BEST PRACTICES
================================================================================

GEOMETRIC AUGMENTATIONS:
- Always include: horizontal flip, rotation
- Consider: vertical flip (if makes sense for your data)
- Avoid: extreme rotations that change meaning

COLOR AUGMENTATIONS:
- Always include: brightness, contrast
- Consider: saturation, hue (but don't overdo it)
- Avoid: inverting colors (changes disease appearance)

SPATIAL AUGMENTATIONS:
- Always include: random crop
- Consider: affine transformations
- Avoid: distortions that make disease unrecognizable

VALIDATION:
- NEVER augment validation/test data
- Only resize, convert to tensor, normalize
- Need consistent results for meaningful metrics

================================================================================
SUMMARY
================================================================================

This file provides a complete data pipeline:

1. PlantDiseaseDataset: Loads images from directory structure
2. get_train_transforms: Augments training data for robustness
3. get_val_transforms: Prepares validation data consistently
4. create_dataloaders: Wraps everything in efficient DataLoaders

Key features:
- Multi-directory support (combine datasets)
- Comprehensive augmentation
- Efficient parallel loading
- Error handling for corrupted images
- Class mapping management
- Train/validation splitting

The pipeline is optimized for speed (multiprocessing, prefetching) and
correctness (reproducible splits, proper normalization, error handling).
